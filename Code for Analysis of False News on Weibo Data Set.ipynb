{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code for analysis of False News on Weibo (and also mentioned comparisons).\n",
    "\n",
    "Required software/language:\n",
    "\n",
    "Python 3.7.3\n",
    "\n",
    "MongoDB 4.2.8\n",
    "\n",
    "Required Python Packages:\n",
    "\n",
    "pymongo==3.7.0\n",
    "\n",
    "pandas==0.23.4\n",
    "\n",
    "numpy==1.15.1\n",
    "\n",
    "scipy=1.1.0\n",
    "\n",
    "seaborn==0.9.0\n",
    "\n",
    "matplotlib==3.1.0\n",
    "\n",
    "\n",
    "The function plot_CCDF() partially refers to the code of (5).\n",
    "The fuctions, kdeplot, _univariate_kdeplot, and _statsmodels_univariate_kde are modified based on the seaborn code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, Settings, and Connection to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T08:12:13.900016Z",
     "start_time": "2021-01-03T08:12:13.830955Z"
    }
   },
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "\n",
    "db = client.weibo_fn\n",
    "og_coll = db.orig_posts\n",
    "rp_coll = db.reposts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:36:12.969092Z",
     "start_time": "2021-01-03T12:36:12.965100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from scipy import integrate, signal, stats\n",
    "import copy\n",
    "\n",
    "try:\n",
    "    import statsmodels.nonparametric.api as smnp\n",
    "    _has_statsmodels = True\n",
    "except ImportError:\n",
    "    _has_statsmodels = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:06:57.818518Z",
     "start_time": "2021-01-03T12:06:57.811519Z"
    }
   },
   "outputs": [],
   "source": [
    "# Figure settings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.transforms as transforms\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "plt.rcParams['font.family']=['Arial']\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 7.5)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "sns.set(rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T08:12:16.006851Z",
     "start_time": "2021-01-03T08:12:16.000548Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_int(x, y):\n",
    "    return integrate.trapz(y, x)\n",
    "\n",
    "def log_10_product(x, pos):\n",
    "    if x<1:\n",
    "        if x>0.009:\n",
    "            return '%1.2f' % (x)  #1.2f\n",
    "        elif x>0.0009:\n",
    "            return '%1.3f' % (x)  #1.2f\n",
    "        elif x>0.00009:\n",
    "            return '%1.4f' % (x)  #1.2f\n",
    "    else:\n",
    "        z='%1i' % (x)\n",
    "        if z=='10000':\n",
    "            return '10K'\n",
    "        elif z=='100000':\n",
    "            return '100K'\n",
    "        elif z=='1000000':\n",
    "            return '1000K'\n",
    "        else:\n",
    "            return z\n",
    "        \n",
    "def abs_loc(x, pos):\n",
    "    return abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:51:50.217929Z",
     "start_time": "2021-01-03T14:51:50.214987Z"
    }
   },
   "outputs": [],
   "source": [
    "ordered_domains = ['Politics', 'Finance & Business', 'Military', \n",
    "                  'Culture & Sports & Entertainment', 'Society & Life', \n",
    "                  'Disasters & Accidents', 'Education & Examinations', 'Science & Technology',\n",
    "                  'Health & Medicine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:51:55.314598Z",
     "start_time": "2021-01-03T14:51:55.311184Z"
    }
   },
   "outputs": [],
   "source": [
    "domain2color ={\n",
    "    'Finance & Business': 'blue',\n",
    "    'Society & Life': 'orange',\n",
    "    'Culture & Sports & Entertainment': 'pink',\n",
    "    'Disasters & Accidents': 'red',\n",
    "    'Science & Technology': 'gray',\n",
    "    'Health & Medicine': 'green',\n",
    "    'Education & Examinations': 'cyan',\n",
    "    'Politics': 'brown',\n",
    "    'Military': 'olive'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain-level Distribution (Fig. 1, Table 11, Section 3.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T08:26:19.922191Z",
     "start_time": "2021-01-03T08:26:19.918576Z"
    }
   },
   "outputs": [],
   "source": [
    "# The Twitter Data from Vosoughi et al [69].\n",
    "domain_dist_tw ={\n",
    "    'Politics': 27600,\n",
    "    'Society & Life': 16458,\n",
    "    'Science & Technology': 12043,\n",
    "    'Finance & Business': 11086,\n",
    "    'Military': 8054,\n",
    "    'Culture & Sports & Entertainment': 6046,\n",
    "    'Disasters & Accidents': 1318,\n",
    "    'Health & Medicine': 0,\n",
    "    'Education & Examinations': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:05:14.500247Z",
     "start_time": "2021-01-03T12:05:13.274602Z"
    }
   },
   "outputs": [],
   "source": [
    "og_coll.update_many({},{'$rename': { \"topic\": \"domain\" }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:36:31.433118Z",
     "start_time": "2021-01-03T12:36:31.055601Z"
    }
   },
   "outputs": [],
   "source": [
    "# The Weibo data.\n",
    "domain_dist_wb = {}\n",
    "\n",
    "for domain in domain_dist_tw.keys():\n",
    "    domain_dist_wb[domain] = og_coll.count_documents({'domain':domain})\n",
    "\n",
    "domain_dist_wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:36:32.808657Z",
     "start_time": "2021-01-03T12:36:32.798392Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spearman's rho in Section 3.4\n",
    "\n",
    "# Nine domains\n",
    "print('9 domains:', spearmanr(list(domain_dist_tw.values()), \n",
    "                             list(domain_dist_wb.values())))\n",
    "\n",
    "# Seven domains (excluding Health & Medicine and Education & Examinations)\n",
    "print('7 domains:', spearmanr(list(domain_dist_tw.values())[:7], \n",
    "                             list(domain_dist_wb.values())[:7]))\n",
    "\n",
    "# merge Health & Medicine into Science & Technology, \n",
    "# and Education & Examinations into Society & Life for alignment\n",
    "domain_dist_wb_merged = copy.deepcopy(domain_dist_wb)\n",
    "domain_dist_wb_merged['Science & Technology'] += domain_dist_wb_merged['Health & Medicine']\n",
    "domain_dist_wb_merged['Society & Life'] += domain_dist_wb_merged['Education & Examinations']\n",
    "print('after merging:', spearmanr(list(domain_dist_tw.values())[:7], \n",
    "                                  list(domain_dist_wb.values())[:7]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:36:34.446488Z",
     "start_time": "2021-01-03T12:36:34.429626Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data for Fig. 1 and Table 12.\n",
    "total_wb = sum(domain_dist_wb.values())\n",
    "total_tw = sum(domain_dist_tw.values())\n",
    "\n",
    "domain_dists  = [{'Domain':domain, \n",
    "                 'Platform':'Twitter',\n",
    "                 'N':domain_dist_tw[domain], \n",
    "                 '%':domain_dist_tw[domain] / total_tw}\n",
    "                for domain in domain_dist_tw.keys()]\n",
    "\n",
    "domain_dists2 = [{'Domain':domain, \n",
    "                 'Platform':'Weibo',\n",
    "                 'N':domain_dist_wb[domain], \n",
    "                 '%':domain_dist_wb[domain] / total_wb}\n",
    "                for domain in domain_dist_tw.keys()]\n",
    "\n",
    "domain_dists.extend(domain_dists2)\n",
    "domain_dists = pd.DataFrame(domain_dists)\n",
    "domain_dists = domain_dists[['Domain', 'Platform', 'N', '%']]\n",
    "domain_dists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:36:40.787056Z",
     "start_time": "2021-01-03T12:36:38.364070Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fig. 1\n",
    "fig, ax = plt.subplots(figsize = (10,7.5))    \n",
    "\n",
    "bplt = sns.barplot(y = domain_dists['Domain'], x = domain_dists[domain_dists['Platform'] == 'Twitter']['%'] * 100, \\\n",
    "                       data = domain_dists, orient = \"h\", color = '#A41088', ax = ax)\n",
    "\n",
    "bplt2 = sns.barplot(y = domain_dists['Domain'], x = domain_dists[domain_dists['Platform'] == 'Weibo']['%'] * -100,\n",
    "                   data = domain_dists, orient = \"h\", color = '#ED693C')\n",
    "\n",
    "bplt.set_xlabel(\"%Posts\", fontsize = 20)\n",
    "bplt.set_ylabel(\"Domain\", fontsize = 20)\n",
    "bplt.set_yticklabels(domain_dists['Domain'], rotation = 0, fontsize = 20)\n",
    "\n",
    "t_patch = mpatches.Patch(color='#A41088', label='Twitter')\n",
    "w_patch = mpatches.Patch(color='#ED693C', label='Weibo')\n",
    "plt.legend(handles=[t_patch, w_patch], loc=4, ncol = 1, prop={'size':20})\n",
    "\n",
    "\n",
    "# for i, d in enumerate(domain_dists['Domain']):\n",
    "#     p = float(domain_dists[(domain_dists['Platform'] == 'Twitter') & (domain_dists['Domain'] == d)]['%'] * 100)\n",
    "#     N = int(domain_dists[(domain_dists['Platform'] == 'Twitter') & (domain_dists['Domain'] == d)]['N'])\n",
    "#     bplt.text(p+0.5, i+0.15, N, fontsize = 15)\n",
    "#     p = float(domain_dists[(domain_dists['Platform'] == 'Weibo') & (domain_dists['Domain'] == d)]['%'] * 100)\n",
    "#     N = int(domain_dists[(domain_dists['Platform'] == 'Weibo') & (domain_dists['Domain'] == d)]['N'])\n",
    "#     bplt2.text(p-3, i+0.15, N, fontsize = 15)\n",
    "    \n",
    "formatter = plt.FuncFormatter(abs_loc)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "ax.xaxis.set_ticklabels([40, 30, 20, 10, 0, 10, 20, 30, 40], fontsize=20)\n",
    "plt.savefig('./figs/fig_1.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion (Section 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:39:23.704217Z",
     "start_time": "2021-01-03T12:39:23.701141Z"
    }
   },
   "outputs": [],
   "source": [
    "ints = {\n",
    "    'Size':{},\n",
    "    'Maximum Depth':{},\n",
    "    'Maximum Breadth':{},\n",
    "    'Number of Engaged Users':{}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:53:25.995297Z",
     "start_time": "2021-01-03T14:53:25.990807Z"
    }
   },
   "outputs": [],
   "source": [
    "def measure_stat(measure_name):\n",
    "    data = {domain:[] for domain in ordered_domains}\n",
    "    \n",
    "    for og in og_coll.find({}):\n",
    "        data[og['domain']].append(int(og[measure_name]))\n",
    "\n",
    "    data_stat = []\n",
    "#     for k, v in data.items():\n",
    "#         data_stat.append({\n",
    "#             'Domain': k,\n",
    "#             'Mean': np.average(v),\n",
    "#             'Standard Error': np.std(v),\n",
    "#             'Min': np.min(v),\n",
    "#             'Median': int(np.median(v)),\n",
    "#             'Max': np.max(v)\n",
    "#         })\n",
    "\n",
    "#     data_stat = pd.DataFrame(data_stat)\n",
    "#     data_stat = data_stat[['Domain', 'Mean', 'Standard Error', 'Min', 'Median', 'Max']]\n",
    "#     return data, data_stat\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:53:05.261263Z",
     "start_time": "2021-01-03T14:53:05.250060Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_CCDF(data, measure_name, output_path):\n",
    "    ax = plt.subplot(111)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    formatter = plt.FuncFormatter(log_10_product)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "    legends = []\n",
    "    for domain, v in data.items():\n",
    "        total=float(len(v))\n",
    "        xf = []\n",
    "        pf = []\n",
    "        v.sort()\n",
    "        counts = list(set(v))\n",
    "        counts.sort()\n",
    "        for d in counts:\n",
    "            ind = v.index(d)\n",
    "            count = len(v[ind:])\n",
    "            p = (count / float(total)) * 100\n",
    "            xf.append(d)\n",
    "            pf.append(p)\n",
    "        ax.plot(xf, pf, '-',color = domain2color[domain], linewidth = 1.5)\n",
    "        try:\n",
    "            ints[measure_name][domain] = get_int(xf, pf)\n",
    "        except:\n",
    "            pass\n",
    "        legends.append(domain)\n",
    "    plt.xlabel(measure_name,fontsize=20)\n",
    "    plt.ylabel(\"CCDF (%)\",fontsize=20)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    plt.xticks(rotation='horizontal')\n",
    "    plt.legend(legends,loc='lower left',fontsize=15,frameon=False)\n",
    "    plt.xlim(xmin=1)\n",
    "    plt.ylim(ymax=100)\n",
    "    plt.savefig(output_path, bbox_inches='tight', format='pdf')\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size (Fig. 2(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:53:30.308222Z",
     "start_time": "2021-01-03T14:53:29.269995Z"
    }
   },
   "outputs": [],
   "source": [
    "sizes = measure_stat('size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:53:34.744005Z",
     "start_time": "2021-01-03T14:53:30.969473Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_CCDF(sizes, 'Size', './figs/fig_2A.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Depth (Fig. 2B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:53:55.994480Z",
     "start_time": "2021-01-03T14:53:54.932453Z"
    }
   },
   "outputs": [],
   "source": [
    "max_depths = measure_stat('max_depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:53:59.420833Z",
     "start_time": "2021-01-03T14:53:56.238460Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_CCDF(max_depths, 'Maximum Depth', './figs/fig_2B.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Breadth (Fig. 2C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:54:04.286989Z",
     "start_time": "2021-01-03T14:54:03.180499Z"
    }
   },
   "outputs": [],
   "source": [
    "max_breadths = measure_stat('max_breadth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:54:10.870030Z",
     "start_time": "2021-01-03T14:54:07.117071Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_CCDF(max_breadths, 'Maximum Breadth', './figs/fig_2C.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Engaged Users (Fig. 2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:54:19.198595Z",
     "start_time": "2021-01-03T14:54:18.131821Z"
    }
   },
   "outputs": [],
   "source": [
    "neu = measure_stat('unique_user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:54:23.698194Z",
     "start_time": "2021-01-03T14:54:19.670577Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_CCDF(neu, 'Number of Engaged Users', './figs/fig_2D.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rankings for Diffusion Capacity (Table 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:54:33.786101Z",
     "start_time": "2021-01-03T14:54:33.756093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normailze Area (NA)\n",
    "normed_ints = {}\n",
    "normed_ints['All measures'] = {domain:0 for domain in ordered_domains}\n",
    "for measure, stat in ints.items():\n",
    "    max_int = np.max(list(stat.values()))\n",
    "    normed_stat = {k : (v / max_int) for k, v in stat.items()}\n",
    "    normed_ints[measure] = normed_stat\n",
    "    normed_ints['All measures'] = {k : normed_ints['All measures'][k] + (v / max_int) \n",
    "                                   for k, v in stat.items()}\n",
    "\n",
    "rank_ints = {}\n",
    "for measure, data in normed_ints.items():\n",
    "    values = list(data.values())\n",
    "    values.sort(reverse=True)\n",
    "    ranks = {k : (int(values.index(v)) + 1) for k, v in data.items()}\n",
    "    rank_ints[measure] = ranks\n",
    "\n",
    "diff_capacity_table = {domain:{} for domain in ordered_domains}\n",
    "measures = ['Size', 'Maximum Depth', 'Maximum Breadth', \n",
    "            'Number of Engaged Users', 'All measures']\n",
    "for domain in ordered_domains:\n",
    "    obj = {}\n",
    "    for mea in measures:\n",
    "        obj[mea + '_NA'] = normed_ints[mea][domain]\n",
    "        obj[mea + '_R'] = rank_ints[mea][domain]\n",
    "    diff_capacity_table[domain] = obj\n",
    "diff_capacity_table = pd.DataFrame(diff_capacity_table).T\n",
    "diff_capacity_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T10:37:22.630161Z",
     "start_time": "2020-06-20T10:37:22.627286Z"
    }
   },
   "source": [
    "# Role of Engaged Users (Section 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T12:12:36.532295Z",
     "start_time": "2020-06-20T12:12:36.529549Z"
    }
   },
   "source": [
    "## User Characteristics (Section 5.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender (Fig. 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T14:38:58.762086Z",
     "start_time": "2021-01-12T14:38:55.731436Z"
    }
   },
   "outputs": [],
   "source": [
    "gender_dist = {domain:{'male': 0, 'female': 0} for domain in ordered_domains}\n",
    "gender_dist['All domains'] = {'male': 0, 'female': 0}\n",
    "for og in og_coll.find({}):\n",
    "    if og['userType'] != 'Verified Organization':\n",
    "        gender_dist[og['domain']][og['userGender']] += 1\n",
    "        gender_dist['All domains'][og['userGender']] += 1\n",
    "for domain in gender_dist.keys():\n",
    "    domain_total = sum(gender_dist[domain].values())\n",
    "    gender_dist[domain]['%male'] = gender_dist[domain]['male'] / domain_total\n",
    "    gender_dist[domain]['%female'] = 1 - gender_dist[domain]['%male']\n",
    "gender_dist['Weibo registered users'] = {'male':'-', 'female':'-', '%male':0.57, '%female':0.43}\n",
    "gender_dist = pd.DataFrame(gender_dist).T\n",
    "gender_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T14:39:08.470111Z",
     "start_time": "2021-01-12T14:39:05.188810Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "sns.set_context({\"figure.figsize\": (10,10)})\n",
    " \n",
    "#Plot 1 - background - \"total\" (top) series\n",
    "top_plot = sns.barplot(y = gender_dist.index, x = np.ones(11) * 100.0, \n",
    "                       orient=\"h\", color='#A41088')\n",
    "\n",
    "#Plot 2 - overlay - \"bottom\" series\n",
    "bottom_plot = sns.barplot(y = gender_dist.index, x = gender_dist['%male']* 100.0, \n",
    "                          orient=\"h\", color='#ED693C')\n",
    "\n",
    "bottom_plot.set_xlabel(\"%user\", fontsize = 20)\n",
    "bottom_plot.set_ylabel(\"Domain\", fontsize = 20)\n",
    "bottom_plot.set_yticklabels(gender_dist.index, rotation=0, fontsize=20)\n",
    "bottom_plot.set_xticklabels([0, 20,40,60,80,100], fontsize=20)\n",
    "bottom_plot.set(xlim=(0,100), ylim=(10.4,-0.4))\n",
    "\n",
    "w_patch = mpatches.Patch(color='#ED693C', label='Male')\n",
    "t_patch = mpatches.Patch(color='#A41088', label='Female')\n",
    "plt.legend(handles=[t_patch, w_patch], loc=4, ncol = 1, prop={'size':20})\n",
    "\n",
    "bottom_plot.vlines(57, -0.4, 10.4, linestyles='--', colors='#ffffff', label='wo')\n",
    "bottom_plot.text(53.8, 10.87, '57', fontsize=20)\n",
    "\n",
    "plt.savefig('./figs/fig_3.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age (Table 3 and Fig. 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:58:31.274228Z",
     "start_time": "2021-01-03T14:58:30.802042Z"
    }
   },
   "outputs": [],
   "source": [
    "# Table 4\n",
    "age_dist = {domain:[] for domain in ordered_domains}\n",
    "age_dist['All domains'] = []\n",
    "for og in og_coll.find({'userBirthYear':{'$ne':-1}}):\n",
    "    # age is calculated when a user published the collected post\n",
    "    age = og['pubYear'] - og['userBirthYear']\n",
    "    if age > 6 and age < 100:\n",
    "        age_dist[og['domain']].append(age)\n",
    "        age_dist['All domains'].append(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:58:33.070463Z",
     "start_time": "2021-01-03T14:58:33.018537Z"
    }
   },
   "outputs": [],
   "source": [
    "age_stat = {domain:{} for domain in ordered_domains}\n",
    "age_stat['All domains'] = {}\n",
    "for domain in age_stat.keys():\n",
    "    age_stat[domain]['Average'] = np.average(age_dist[domain])\n",
    "    age_stat[domain]['Upper Quartile'] = np.quantile(age_dist[domain], .75)\n",
    "    age_stat[domain]['N(<30)'] = np.sum(list(map(lambda x : x < 30, age_dist[domain])))\n",
    "    age_stat[domain]['N(30~65)'] = np.sum(list(map(lambda x : x >= 30 and x <= 65, age_dist[domain])))\n",
    "    age_stat[domain]['N(>65)'] = np.sum(list(map(lambda x : x >= 65, age_dist[domain])))\n",
    "    total = len(age_dist[domain])\n",
    "    age_stat[domain]['%(<30)'] = age_stat[domain]['N(<30)'] / total\n",
    "    age_stat[domain]['%(30~65)'] = age_stat[domain]['N(30~65)'] / total\n",
    "    age_stat[domain]['%(>65)'] = age_stat[domain]['N(>65)'] / total   \n",
    "age_stat = pd.DataFrame(age_stat).T\n",
    "age_stat = age_stat[['Average', 'Upper Quartile', 'N(<30)', '%(<30)', 'N(30~65)', '%(30~65)',\n",
    "             'N(>65)', '%(>65)']]\n",
    "age_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T14:59:55.920366Z",
     "start_time": "2021-01-03T14:59:55.897592Z"
    }
   },
   "outputs": [],
   "source": [
    "def kdeplot(data, data2=None, shade=False, vertical=False, kernel=\"gau\",\n",
    "            bw=\"scott\", gridsize=100, cut=3, clip=None, legend=True,\n",
    "            cumulative=False, shade_lowest=True, cbar=False, cbar_ax=None,\n",
    "            cbar_kws=None, ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    if isinstance(data, list):\n",
    "        data = np.asarray(data)\n",
    "\n",
    "    data = data.astype(np.float64)\n",
    "    if data2 is not None:\n",
    "        if isinstance(data2, list):\n",
    "            data2 = np.asarray(data2)\n",
    "        data2 = data2.astype(np.float64)\n",
    "\n",
    "    ax = _univariate_kdeplot(data, shade, vertical, kernel, bw, gridsize, cut, clip, legend, ax,\n",
    "                             cumulative=cumulative, **kwargs)\n",
    "\n",
    "    return ax\n",
    "\n",
    "def _univariate_kdeplot(data, shade, vertical, kernel, bw, gridsize, cut,\n",
    "                        clip, legend, ax, cumulative=False, **kwargs):\n",
    "    \"\"\"Plot a univariate kernel density estimate on one of the axes.\"\"\"\n",
    "    \n",
    "    print(data.shape)\n",
    "    # Sort out the clipping\n",
    "    if clip is None:\n",
    "        clip = (-np.inf, np.inf)\n",
    "\n",
    "    # Calculate the KDE\n",
    "\n",
    "    if np.nan_to_num(data.var()) == 0:\n",
    "        # Don't try to compute KDE on singular data\n",
    "        msg = \"Data must have variance to compute a kernel density estimate.\"\n",
    "        warnings.warn(msg, UserWarning)\n",
    "        x, y = np.array([]), np.array([])\n",
    "\n",
    "    elif _has_statsmodels:\n",
    "        # Prefer using statsmodels for kernel flexibility\n",
    "        x, y = _statsmodels_univariate_kde(data, kernel, bw,\n",
    "                                           gridsize, cut, clip,\n",
    "                                           cumulative=cumulative)\n",
    "    else:\n",
    "        # Fall back to scipy if missing statsmodels\n",
    "        if kernel != \"gau\":\n",
    "            kernel = \"gau\"\n",
    "            msg = \"Kernel other than `gau` requires statsmodels.\"\n",
    "            warnings.warn(msg, UserWarning)\n",
    "        if cumulative:\n",
    "            raise ImportError(\"Cumulative distributions are currently \"\n",
    "                              \"only implemented in statsmodels. \"\n",
    "                              \"Please install statsmodels.\")\n",
    "        x, y = _scipy_univariate_kde(data, bw, gridsize, cut, clip)\n",
    "\n",
    "    # Make sure the density is nonnegative\n",
    "    y = np.amax(np.c_[np.zeros_like(y), y], axis=1)\n",
    "\n",
    "    # Flip the data if the plot should be on the y axis\n",
    "    if vertical:\n",
    "        x, y = y, x\n",
    "\n",
    "    # Check if a label was specified in the call\n",
    "    label = kwargs.pop(\"label\", None)\n",
    "\n",
    "    # Otherwise check if the data object has a name\n",
    "    if label is None and hasattr(data, \"name\"):\n",
    "        label = data.name\n",
    "\n",
    "    # Decide if we're going to add a legend\n",
    "    legend = label is not None and legend\n",
    "    label = \"_nolegend_\" if label is None else label\n",
    "\n",
    "    # Use the active color cycle to find the plot color\n",
    "    facecolor = kwargs.pop(\"facecolor\", None)\n",
    "    line, = ax.plot(x, y, **kwargs)\n",
    "    color = line.get_color()\n",
    "    line.remove()\n",
    "    kwargs.pop(\"color\", None)\n",
    "    facecolor = color if facecolor is None else facecolor\n",
    "\n",
    "    # Draw the KDE plot and, optionally, shade\n",
    "    shade_kws = dict(alpha=1, cmap='plasma')\n",
    "    if shade:\n",
    "        colors= plt.get_cmap('plasma_r')(norm(x))\n",
    "        for i in range(x.shape[0]-1):\n",
    "            ax.fill_between(x[i:], y[i:], color = colors[i])\n",
    "\n",
    "    # Set the density axis minimum to 0\n",
    "    if vertical:\n",
    "        ax.set_xlim(0, auto=None)\n",
    "    else:\n",
    "        ax.set_ylim(0, auto=None)\n",
    "\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize = 20)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize = 20)\n",
    "\n",
    "    return ax\n",
    "\n",
    "def _statsmodels_univariate_kde(data, kernel, bw, gridsize, cut, clip,\n",
    "                                cumulative=False):\n",
    "    \"\"\"Compute a univariate kernel density estimate using statsmodels.\"\"\"\n",
    "    fft = kernel == \"gau\"\n",
    "    kde = smnp.KDEUnivariate(data)\n",
    "    kde.fit(kernel, bw, fft, gridsize=gridsize, cut=cut, clip=clip)\n",
    "    if cumulative:\n",
    "        grid, y = kde.support, kde.cdf\n",
    "    else:\n",
    "        grid, y = kde.support, kde.density\n",
    "    return grid, y\n",
    "\n",
    "def norm(x):\n",
    "    _range = np.max(x) - np.min(x)\n",
    "    return (x - np.min(x)) / _range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:00:26.446888Z",
     "start_time": "2021-01-03T15:00:12.449082Z"
    }
   },
   "outputs": [],
   "source": [
    "# Figure 4\n",
    "age_dist_list = []\n",
    "for domain, ages in age_dist.items():\n",
    "    for age in ages:\n",
    "        age_dist_list.append({'Domain':domain, 'Age':age})\n",
    "age_dist_list = pd.DataFrame(age_dist_list)\n",
    "sns.set_context({\"figure.figsize\": (10, 10)})\n",
    "\n",
    "domain_order = ['Politics', 'Military', 'Finance & Business', 'Culture & Sports & Entertainment', \n",
    "               'Science & Technology', 'Health & Medicine', 'Society & Life', \n",
    "               'Education & Examinations','Disasters & Accidents', 'All domains']\n",
    "\n",
    "pal = sns.cubehelix_palette(10, light=.7, reverse = True)\n",
    "\n",
    "age_plot = sns.FacetGrid(age_dist_list, row=\"Domain\", hue=\"Domain\", \n",
    "                         aspect=10, height=1.5, xlim=(0,100),\n",
    "                         sharex=True, sharey=True, \n",
    "                         row_order = domain_order)\n",
    "age_plot = age_plot.map(kdeplot, \"Age\", clip_on=False, shade=True, alpha=1)\n",
    "\n",
    "age_plot.fig.subplots_adjust(hspace=.05)\n",
    "\n",
    "age_plot.fig.text(0.65, 0.9, 'Politics', fontsize=20)\n",
    "age_plot.fig.text(0.65, 0.81, 'Military', fontsize=20)\n",
    "age_plot.fig.text(0.65, 0.72, 'Finance & Business', fontsize=20)\n",
    "age_plot.fig.text(0.65, 0.63, 'Culture & Sports & Entertainment', fontsize=20)\n",
    "age_plot.fig.text(0.65, 0.535, 'Science & Technology', fontsize=20)\n",
    "age_plot.fig.text(0.65, 0.445, 'Health & Medicine', fontsize=20)\n",
    "age_plot.fig.text(0.65, 0.35, 'Society & Life', fontsize=20)\n",
    "age_plot.fig.text(0.65, 0.26, 'Education & Examinations', fontsize=20)\n",
    "age_plot.fig.text(0.65, 0.17, 'Disasters & Accidents', fontsize=20)\n",
    "age_plot.fig.text(0.65, 0.08, 'All domains', fontsize=20)\n",
    "\n",
    "age_plot.set_titles(\"\")\n",
    "age_plot.set(yticks=[])\n",
    "age_plot.despine(left=True)\n",
    "\n",
    "plt.savefig('./figs/fig_4.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Account (Table 4, 5, and 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:02:37.555703Z",
     "start_time": "2021-01-03T15:02:35.437019Z"
    }
   },
   "outputs": [],
   "source": [
    "account_dist = {domain:{} for domain in ordered_domains}\n",
    "account_dist['All domains'] = {}\n",
    "type_order = ['Unverified User', 'Verified Individual',\n",
    "             'Verified Organization']\n",
    "total_st_cnt = [0, 0, 0]\n",
    "total_rp_cnt = [0, 0, 0]\n",
    "\n",
    "for domain in ordered_domains:\n",
    "    st_cnt = [0, 0, 0]\n",
    "    rp_cnt = [0, 0, 0]\n",
    "    \n",
    "    for og in og_coll.find({\n",
    "        'domain':domain,\n",
    "        'userType':{'$in':['Ordinary User','Active Ordinary User']}\n",
    "    }):\n",
    "        st_cnt[0] += 1\n",
    "        rp_cnt[0] += og['size']\n",
    "    for og in og_coll.find({\n",
    "        'domain':domain,\n",
    "        'userType':'Verified Individual'\n",
    "    }):\n",
    "        st_cnt[1] += 1\n",
    "        rp_cnt[1] += og['size']\n",
    "    for og in og_coll.find({\n",
    "        'domain':domain,\n",
    "        'userType':'Verified Organization'\n",
    "    }):\n",
    "        st_cnt[2] += 1\n",
    "        rp_cnt[2] += og['size']\n",
    "    rp_cnt = [rp_cnt[i] - st_cnt[i] for i in range(3)]\n",
    "    total_st_cnt = [total_st_cnt[i] + st_cnt[i] for i in range(3)]\n",
    "    total_rp_cnt = [total_rp_cnt[i] + rp_cnt[i] for i in range(3)]\n",
    "    st_p = [st_cnt[i] / sum(st_cnt)  for i in range(3)]\n",
    "    rp_p = [rp_cnt[i] / sum(rp_cnt)  for i in range(3)]\n",
    "    \n",
    "    for i in range(3):\n",
    "        account_dist[domain][type_order[i] + '_%rp'] = rp_p[i]\n",
    "        account_dist[domain][type_order[i] + '_%st'] = st_p[i]\n",
    "        \n",
    "# Calculate the total\n",
    "total_st_p = [total_st_cnt[i] / sum(total_st_cnt)  for i in range(3)]\n",
    "total_rp_p = [total_rp_cnt[i] / sum(total_rp_cnt)  for i in range(3)]\n",
    "for i in range(3):\n",
    "    account_dist['All domains'][type_order[i] + '_%rp'] = total_rp_p[i]\n",
    "    account_dist['All domains'][type_order[i] + '_%st'] = total_st_p[i]\n",
    "        \n",
    "account_dist = pd.DataFrame(account_dist).T\n",
    "account_dist = account_dist[\n",
    "    ['Unverified User_%st', 'Unverified User_%rp',\n",
    "     'Verified Individual_%st', 'Verified Individual_%rp',\n",
    "     'Verified Organization_%st', 'Verified Organization_%rp']\n",
    "]\n",
    "account_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:02:15.210189Z",
     "start_time": "2021-01-03T15:01:55.464784Z"
    }
   },
   "outputs": [],
   "source": [
    "org_repost_beliefs = {}\n",
    "global_aggs = {k:0 for k in rp_coll.distinct('label')}\n",
    "\n",
    "beliefs_order = ['believe', 'debunk', 'DNB', 'doubt', 'unknown']\n",
    "orgs_order = ['Police', 'Government', 'Media', 'Company',\n",
    "              'School', 'Social Org.', 'Total']\n",
    "\n",
    "match = {'userType':'Verified Organization'}\n",
    "group = {'_id':'$userDomain', 'label':{'$sum':1}}\n",
    "\n",
    "for udom in rp_coll.distinct('userDomain', match):\n",
    "    aggs = {}\n",
    "    for agg in rp_coll.aggregate([{'$match':{'userType':'Verified Organization',\n",
    "                                             'userDomain':udom}},\n",
    "                                  {'$group':{'_id':'$label', \n",
    "                                             'label':{'$sum':1}}}]):\n",
    "        aggs[agg['_id']] = agg['label']\n",
    "        global_aggs[agg['_id']] += agg['label']\n",
    "    local_total = sum(aggs.values())\n",
    "    normed_aggs = {k:v/local_total for k,v in aggs.items()}\n",
    "    org_repost_beliefs[udom] = normed_aggs\n",
    "global_total = sum(global_aggs.values())\n",
    "org_repost_beliefs['Total'] = {k:v/global_total for k,v in global_aggs.items()}\n",
    "\n",
    "org_repost_beliefs = pd.DataFrame(org_repost_beliefs).T\n",
    "org_repost_beliefs = org_repost_beliefs[beliefs_order]\n",
    "org_repost_beliefs = org_repost_beliefs.T\n",
    "org_repost_beliefs = org_repost_beliefs[orgs_order]\n",
    "org_repost_beliefs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:04:20.325249Z",
     "start_time": "2021-01-03T15:03:36.326408Z"
    }
   },
   "outputs": [],
   "source": [
    "org_fooled_dist = {domain:{'Number of the fooling-organization posts':0} \n",
    "                   for domain in ordered_domains}\n",
    "fooling_org_posts_total = 0\n",
    "column_order = [\n",
    "    'Number of the fooling-organization posts',\n",
    "    'Proportion of the fooling-organization posts',\n",
    "    'Number of all reposted false original posts',\n",
    "    'Proportion of all reposted false original posts',\n",
    "    'Difference'\n",
    "]\n",
    "\n",
    "repostedIds = set()\n",
    "for rp in rp_coll.find({'userType' : 'Verified Organization',\n",
    "                        'label':'believe'}):\n",
    "    repostedIds.add(rp['forwardedId'])\n",
    "\n",
    "for rpid in repostedIds:\n",
    "    domain = og_coll.find_one({'weiboId':rpid})['domain']\n",
    "    org_fooled_dist[domain]['Number of the fooling-organization posts'] += 1\n",
    "    fooling_org_posts_total +=1\n",
    "\n",
    "og_total = og_coll.count_documents({'size':{'$gt':1}})\n",
    "\n",
    "for domain in ordered_domains:\n",
    "    org_fooled_dist[domain]['Proportion of the fooling-organization posts']=\\\n",
    "    org_fooled_dist[domain]['Number of the fooling-organization posts'] / fooling_org_posts_total\n",
    "    \n",
    "    org_fooled_dist[domain]['Number of all reposted false original posts'] = \\\n",
    "    og_coll.count_documents({'domain':domain, 'size':{'$gt':1}})\n",
    "    \n",
    "    org_fooled_dist[domain]['Proportion of all reposted false original posts'] = \\\n",
    "    org_fooled_dist[domain]['Number of all reposted false original posts'] / og_total\n",
    "    \n",
    "    org_fooled_dist[domain]['Difference'] = \\\n",
    "    org_fooled_dist[domain]['Proportion of the fooling-organization posts'] - \\\n",
    "    org_fooled_dist[domain]['Proportion of all reposted false original posts']\n",
    "    \n",
    "org_fooled_dist = pd.DataFrame(org_fooled_dist).T\n",
    "org_fooled_dist = org_fooled_dist[column_order]\n",
    "org_fooled_dist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Emotions (Section 5.2, Fig. 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:05:04.101892Z",
     "start_time": "2021-01-03T15:05:04.097832Z"
    }
   },
   "outputs": [],
   "source": [
    "emotions = ['disgust', 'like', 'anger', 'sadness', 'surprise', 'joy', 'fear']\n",
    "emotions_cap = ['Disgust', 'Like', 'Anger', 'Sadness', 'Surprise', 'Joy', 'Fear']\n",
    "diff_capacity = [1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole Emotional Intensity (Section 5.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:05:10.275928Z",
     "start_time": "2021-01-03T15:05:08.914787Z"
    }
   },
   "outputs": [],
   "source": [
    "# Original Posts\n",
    "orig_post_emo_int = {t:0 for t in ordered_domains}\n",
    "\n",
    "for og in og_coll.find({}):\n",
    "    orig_post_emo_int[og['domain']] += og['emo_weiboContent']['total']\n",
    "\n",
    "orig_post_emo_int = {t:orig_post_emo_int[t] / og_coll.count_documents({'domain':t})\n",
    "                     for t in ordered_domains}\n",
    "\n",
    "sorted_orig_post_emo_int = list(orig_post_emo_int.values())\n",
    "sorted_orig_post_emo_int.sort(reverse=True)\n",
    "orig_post_emo_int_rank = [sorted_orig_post_emo_int.index(v)+1 for v in orig_post_emo_int.values()]\n",
    "\n",
    "print(orig_post_emo_int_rank)\n",
    "print(spearmanr(diff_capacity, orig_post_emo_int_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:05:20.638354Z",
     "start_time": "2021-01-03T15:05:18.637084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reposts\n",
    "rp_domain = {domain:0 for domain in ordered_domains}\n",
    "for t in ordered_domains:\n",
    "    for og in og_coll.find({'domain':t}):\n",
    "        rp_domain[t] += (og['size'] - 1)\n",
    "\n",
    "repost_emo_int = {domain:0 for domain in ordered_domains}\n",
    "\n",
    "for og in og_coll.find({'size':{'$gt':1}}):\n",
    "    repost_emo_int[og['domain']] += og['emo_reposts']['total']\n",
    "    \n",
    "repost_emo_int = {t:repost_emo_int[t] / rp_domain[t]\n",
    "                   for t in ordered_domains}\n",
    "\n",
    "sorted_repost_emo_int = list(repost_emo_int.values())\n",
    "sorted_repost_emo_int.sort(reverse=True)\n",
    "repost_emo_int_rank = [sorted_repost_emo_int.index(v)+1 for v in repost_emo_int.values()]\n",
    "\n",
    "print(repost_emo_int_rank)\n",
    "print(spearmanr(diff_capacity,repost_emo_int_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion Ranks of the Domains (Table 13, Table 14, and Figure 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:27:18.944801Z",
     "start_time": "2021-01-03T15:27:17.018336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Emotion distribution for the original posts\n",
    "# Table 13\n",
    "orig_post_emo_dist = {domain:{emo:0 for emo in emotions} for domain in ordered_domains}\n",
    "\n",
    "for og in og_coll.find({}):\n",
    "    for emo in emotions:\n",
    "        if  og['emo_weiboContent']['total'] != 0:\n",
    "            orig_post_emo_dist[og['domain']][emo] += (og['emo_weiboContent'][emo] / og['emo_weiboContent']['total'])\n",
    "\n",
    "for domain in ordered_domains:\n",
    "    domain_n = og_coll.count_documents({'domain':domain})\n",
    "    orig_post_emo_dist[domain] = {e:(v / domain_n) for e, v in orig_post_emo_dist[domain].items()}\n",
    "    \n",
    "orig_post_emo_dist = pd.DataFrame(orig_post_emo_dist).T\n",
    "orig_post_emo_dist = orig_post_emo_dist[emotions]\n",
    "orig_post_emo_dist.columns = [emotions_cap]\n",
    "orig_post_emo_dist\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:25:23.672586Z",
     "start_time": "2021-01-03T15:25:23.653440Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fig. 5(Left)\n",
    "orig_post_emo_rank = {emo:{} for emo in emotions_cap}\n",
    "for emo in emotions_cap:\n",
    "    emo_vals = [v[0] for v in orig_post_emo_dist[emo].values.tolist()]\n",
    "    sorted_emo_vals = copy.deepcopy(emo_vals)\n",
    "    sorted_emo_vals.sort(reverse=True)\n",
    "    orig_post_emo_rank[emo] = {ordered_domains[i]:sorted_emo_vals.index(emo_vals[i])+1 \\\n",
    "                               for i in range(len(ordered_domains))}\n",
    "\n",
    "orig_post_emo_rank = pd.DataFrame(orig_post_emo_rank).T\n",
    "orig_post_emo_rank = orig_post_emo_rank[ordered_domains].T\n",
    "orig_post_emo_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:25:30.356405Z",
     "start_time": "2021-01-03T15:25:30.341670Z"
    }
   },
   "outputs": [],
   "source": [
    "# Caption of Table 13\n",
    "for e in emotions_cap:\n",
    "    print(e, spearmanr(orig_post_emo_rank[e], diff_capacity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:27:50.722388Z",
     "start_time": "2021-01-03T15:27:49.713237Z"
    }
   },
   "outputs": [],
   "source": [
    "# Emotion distribution for the reposts\n",
    "# Table 14\n",
    "repost_emo_dist = {domain:{emo:0 for emo in emotions} for domain in ordered_domains}\n",
    "\n",
    "for og in og_coll.find({'size':{'$gt':1}}):\n",
    "    for emo in emotions:\n",
    "        if  og['emo_reposts']['total'] != 0:\n",
    "            repost_emo_dist[og['domain']][emo] += (og['emo_reposts'][emo] / og['emo_reposts']['total'])\n",
    "\n",
    "for domain in ordered_domains:\n",
    "    domain_n = og_coll.count_documents({'domain':domain})\n",
    "    repost_emo_dist[domain] = {e:(v / domain_n) for e, v in repost_emo_dist[domain].items()}\n",
    "    \n",
    "repost_emo_dist = pd.DataFrame(repost_emo_dist).T\n",
    "repost_emo_dist = repost_emo_dist[emotions]\n",
    "repost_emo_dist.columns = [emotions_cap]\n",
    "repost_emo_dist\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:41:51.071011Z",
     "start_time": "2021-01-03T15:41:51.052180Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fig. 5 (Middle)\n",
    "repost_emo_rank = {emo:{} for emo in emotions_cap}\n",
    "for emo in emotions_cap:\n",
    "    emo_vals = [v[0] for v in repost_emo_dist[emo].values.tolist()]\n",
    "    sorted_emo_vals = copy.deepcopy(emo_vals)\n",
    "    sorted_emo_vals.sort(reverse=True)\n",
    "    repost_emo_rank[emo] = {ordered_domains[i]:sorted_emo_vals.index(emo_vals[i])+1 \\\n",
    "                               for i in range(len(ordered_domains))}\n",
    "\n",
    "repost_emo_rank = pd.DataFrame(repost_emo_rank).T\n",
    "repost_emo_rank = repost_emo_rank[ordered_domains].T\n",
    "repost_emo_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:41:49.050527Z",
     "start_time": "2021-01-03T15:41:49.039572Z"
    }
   },
   "outputs": [],
   "source": [
    "# Caption of Table 14\n",
    "for e in emotions_cap:\n",
    "    print(e, spearmanr(repost_emo_rank[e], diff_capacity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:28:34.075166Z",
     "start_time": "2021-01-03T15:28:27.864285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fig. 5 Plot\n",
    "fig = plt.figure(tight_layout=True, figsize=(19,9))\n",
    "gs = gridspec.GridSpec(1,9)\n",
    "\n",
    "# subplot 1 (Left)\n",
    "ax = fig.add_subplot(gs[0,0:4])\n",
    "orig_post_emo_rank_ht = sns.heatmap(data=orig_post_emo_rank, cbar=False, annot=True, annot_kws={\"size\": 15})\n",
    "\n",
    "\n",
    "orig_post_emo_rank_ht.set_xlabel(\"Emotion of the Original Posts\", fontsize = 15)\n",
    "orig_post_emo_rank_ht.set_ylabel(\"Domain\", fontsize = 15)\n",
    "orig_post_emo_rank_ht.set_xticklabels(orig_post_emo_rank_ht.get_xticklabels(), fontsize = 15)\n",
    "orig_post_emo_rank_ht.set_yticklabels(orig_post_emo_rank_ht.get_yticklabels(), fontsize = 15)\n",
    "\n",
    "# subplot 2 (Middle)\n",
    "ax = fig.add_subplot(gs[0,4:8])\n",
    "repost_emo_rank_ht = sns.heatmap(data=repost_emo_rank, cbar=False, annot=True, annot_kws={\"size\": 15})\n",
    "\n",
    "repost_emo_rank_ht.set_xlabel(\"Emotion of the Reposts\", fontsize = 15)\n",
    "repost_emo_rank_ht.set_xticklabels(repost_emo_rank_ht.get_xticklabels(), fontsize = 15)\n",
    "repost_emo_rank_ht.set_yticklabels([])\n",
    "\n",
    "# subplot 3 (Right)\n",
    "ax = fig.add_subplot(gs[0,8])\n",
    "base = plt.gca().transData\n",
    "rot = transforms.Affine2D().rotate_deg_around(3.5, 4.5, 270)\n",
    "# ax = axes[2]\n",
    "line_diffusion = ax.plot(range(9), color='#690098', alpha=.5, transform = rot + base)\n",
    "ax.fill_between(x = range(0,9,1), y1 = range(9), color='#690098',\n",
    "                alpha=.1, transform = rot + base)\n",
    "\n",
    "line_orig_post = ax.plot(np.array(orig_post_emo_int_rank) - 1, '--', color='#F38A3E', alpha=.5, transform = rot + base)\n",
    "ax.fill_between(x = range(0,9,1), y1 = np.array(orig_post_emo_int_rank) - 1, color='#F38A3E',\n",
    "                alpha=.4, transform = rot + base)\n",
    "\n",
    "line_repost = ax.plot(np.array(repost_emo_int_rank) - 1, '-.', color='#BE2F65', alpha=.5, transform = rot + base)\n",
    "ax.fill_between(x = range(0,9,1), y1 = np.array(repost_emo_int_rank) - 1, color='#BE2F65',\n",
    "                alpha=.4, transform = rot + base)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "plt.legend(['Diffusion', 'Orig. Post EI', 'Repost EI'], \n",
    "           bbox_to_anchor=(0.5, 0.04),loc='upper center', borderaxespad=0,\n",
    "           frameon=False, labelspacing=-0.01, borderpad=0)\n",
    "plt.xticks([0, 7], ( '1','9'))\n",
    "plt.xlabel('Rank', fontsize=15)\n",
    "plt.yticks([])\n",
    "\n",
    "\n",
    "plt.savefig('./figs/fig_5.pdf', bbox_inches='tight', format='pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Behaviors (Table 7, 8, and 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Reposts for Reply (Table 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:31:50.201123Z",
     "start_time": "2021-01-03T15:31:49.583164Z"
    }
   },
   "outputs": [],
   "source": [
    "reply_dist = {domain:[] for domain in ordered_domains}\n",
    "reply_dist['Total'] = []\n",
    "\n",
    "for og in og_coll.find({'gotForward':{'$gt':0}}):\n",
    "    reply_dist[og['domain']].append(og['replyCnt'])\n",
    "    reply_dist['Total'].append(og['replyCnt'])\n",
    "    \n",
    "data_stat = []\n",
    "for k, v in reply_dist.items():\n",
    "    data_stat.append({\n",
    "        'Domain': k,\n",
    "        'Mean': np.average(v),\n",
    "        'Standard Error': np.std(v)\n",
    "    })\n",
    "data_stat = pd.DataFrame(data_stat)\n",
    "data_stat = data_stat[['Domain', 'Mean', 'Standard Error']]\n",
    "data_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cascade Concentration (Table 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:31:53.735714Z",
     "start_time": "2021-01-03T15:31:52.470249Z"
    }
   },
   "outputs": [],
   "source": [
    "cc_dist = {domain:[] for domain in ordered_domains}\n",
    "cc_dist['Total'] = []\n",
    "\n",
    "for og in og_coll.find({}):\n",
    "    cc_dist[og['domain']].append(og['concentration'])\n",
    "    cc_dist['Total'].append(og['concentration'])\n",
    "    \n",
    "data_stat = []\n",
    "for k, v in cc_dist.items():\n",
    "    data_stat.append({\n",
    "        'Domain': k,\n",
    "        'Mean': np.average(v) * 100.0\n",
    "    })\n",
    "data_stat = pd.DataFrame(data_stat)\n",
    "data_stat = data_stat[['Domain', 'Mean']]\n",
    "data_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starter Engagement (Table 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:33:28.211119Z",
     "start_time": "2021-01-15T06:33:27.605258Z"
    }
   },
   "outputs": [],
   "source": [
    "se_dist = {domain:[] for domain in ordered_domains}\n",
    "\n",
    "for og in og_coll.find({'gotForward':{'$gt':0}}):\n",
    "    se_dist[og['domain']].append(og['starterRepostCnt'] + 1)\n",
    "\n",
    "se_ints = {domain:0  for domain in ordered_domains}\n",
    "for domain, se in se_dist.items():\n",
    "    total=float(len(se))\n",
    "    xf = []\n",
    "    pf = []\n",
    "    se.sort()\n",
    "    counts = list(set(se))\n",
    "    counts.sort()\n",
    "    for d in counts:\n",
    "        ind = se.index(d)\n",
    "        count = len(se[ind:])\n",
    "        p = (count / float(total)) * 100\n",
    "        xf.append(d) \n",
    "        pf.append(p)\n",
    "    se_ints[domain] = get_int(xf, pf)\n",
    "    \n",
    "normed_se_ints = {domain : (se_ints[domain] / max(se_ints.values())) \n",
    "                  for domain in ordered_domains}\n",
    "values = list(normed_se_ints.values())\n",
    "values.sort(reverse=True)\n",
    "rank_se_ints = {k : (int(values.index(v)) + 1) for k, v in normed_se_ints.items()}\n",
    "\n",
    "data_stat = {}\n",
    "for k, v in se_dist.items():\n",
    "    l = len(se_dist[k])\n",
    "    data_stat[k]={\n",
    "        'Mean': np.average(v),\n",
    "        'Standard Error': np.std(v),\n",
    "        'Min': np.min(v),\n",
    "        'Median': int(np.median(v)),\n",
    "        'Max': np.max(v),\n",
    "        '% of having >= 1 repost': np.sum(list(map(lambda x : x >= 2, se_dist[k]))) / l * 100.0,\n",
    "#         '% of having >= 5 reposts': np.sum(list(map(lambda x : x >= 6, se_dist[k]))) / l * 100.0,\n",
    "        '% of having >= 10 reposts': np.sum(list(map(lambda x : x >= 11, se_dist[k]))) / l * 100.0,\n",
    "        'NA':normed_se_ints[k], \n",
    "        'R': rank_se_ints[k],\n",
    "    }\n",
    "data_stat = pd.DataFrame(data_stat).T\n",
    "data_stat = data_stat[['Mean', 'Standard Error', \n",
    "                       'Min', 'Median', 'Max',\n",
    "                       '% of having >= 1 repost', \n",
    "#                        '% of having >= 5 reposts', \n",
    "                       '% of having >= 10 reposts',\n",
    "                       'NA', 'R']]\n",
    "data_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starters' Reposts Content Analysis (Table 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:36:06.983494Z",
     "start_time": "2021-01-03T15:36:06.822012Z"
    }
   },
   "outputs": [],
   "source": [
    "st_repost_dist = {domain:{'Number of cascades in which starters expressed disbeliefs':0,\n",
    "                         'Number of cascades that starters reposted':0} \n",
    "                   for domain in ordered_domains}\n",
    "st_repost_dist['All domains'] =  \\\n",
    "    {'Number of cascades in which starters expressed disbeliefs':0, \\\n",
    "     'Number of cascades that starters reposted':0} \n",
    "column_order = ['Number of cascades in which starters expressed disbeliefs',\n",
    "                'Number of cascades that starters reposted',\n",
    "                'Disbelief rate',\n",
    "                'Rank']\n",
    "\n",
    "for og in og_coll.find({'starterRerpostBeliefs':{'$exists':True}}):\n",
    "    st_repost_dist[og['domain']]['Number of cascades that starters reposted'] += 1\n",
    "    st_repost_dist['All domains']['Number of cascades that starters reposted'] += 1\n",
    "    beliefs = og['starterRerpostBeliefs']\n",
    "    if 'DNB' in beliefs or 'doubt' in beliefs or 'debunk' in beliefs:\n",
    "        st_repost_dist[og['domain']]['Number of cascades in which starters expressed disbeliefs'] += 1\n",
    "        st_repost_dist['All domains']['Number of cascades in which starters expressed disbeliefs'] += 1\n",
    "\n",
    "for domain in st_repost_dist.keys():\n",
    "    st_repost_dist[domain]['Disbelief rate'] = \\\n",
    "    st_repost_dist[domain]['Number of cascades in which starters expressed disbeliefs'] / \\\n",
    "    st_repost_dist[domain]['Number of cascades that starters reposted']\n",
    "\n",
    "rates = []\n",
    "for domain in ordered_domains:\n",
    "    rates.append(st_repost_dist[domain]['Disbelief rate'])\n",
    "rates.sort(reverse=True)\n",
    "for domain in ordered_domains:\n",
    "    st_repost_dist[domain]['Rank'] = rates.index(st_repost_dist[domain]['Disbelief rate']) + 1 \n",
    "\n",
    "st_repost_dist = pd.DataFrame(st_repost_dist).T\n",
    "st_repost_dist = st_repost_dist[column_order]\n",
    "st_repost_dist\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
